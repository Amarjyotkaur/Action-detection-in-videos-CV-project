{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c322f8a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.CNN import CNN\n",
    "from models.RNN import RNN\n",
    "from models.two_stream import two_stream_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707ad571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_size(input_size, kernel_size, stride=1, padding=0, dilation=1):\n",
    "    output_size = (input_size + 2*padding - dilation*(kernel_size-1) - 1) / stride + 1\n",
    "    if not output_size.is_integer():\n",
    "        print(f'Fractional output size: {output_size}')\n",
    "    return int(output_size)\n",
    "\n",
    "# Functions to check Conv2d and ConvTranspose2d architecture output size\n",
    "def check_Conv2d_architecture(input_size, conv_layers):\n",
    "    print(f'# In: {input_size} x {input_size}')\n",
    "    for conv_layer in conv_layers:\n",
    "        output_size = conv_output_size(input_size, *conv_layer)\n",
    "        print(f\"nn.Conv2d(..., {str(conv_layer).strip('()')}), # {output_size} x {output_size}\")\n",
    "        input_size = output_size\n",
    "    print(f'# Out: {output_size} x {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15dde80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 216\n",
    "num_classes = 174"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa96d98",
   "metadata": {},
   "source": [
    "## LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d223c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# In: 216 x 216\n",
      "nn.Conv2d(..., 7, 1, 0), # 210 x 210\n",
      "nn.Conv2d(..., 2, 2, 0), # 105 x 105\n",
      "nn.Conv2d(..., 5, 1, 0), # 101 x 101\n",
      "Fractional output size: 50.5\n",
      "nn.Conv2d(..., 2, 2, 0), # 50 x 50\n",
      "nn.Conv2d(..., 3, 1, 0), # 48 x 48\n",
      "nn.Conv2d(..., 3, 1, 0), # 46 x 46\n",
      "nn.Conv2d(..., 3, 1, 0), # 44 x 44\n",
      "nn.Conv2d(..., 2, 2, 0), # 22 x 22\n",
      "# Out: 22 x 22\n",
      "CNN output shape: torch.Size([32, 174])\n",
      "RNN output shape: torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "check_Conv2d_architecture(input_size, [\n",
    "    (7, 1, 0), # conv1\n",
    "    (2, 2, 0), # pool1\n",
    "    (5, 1, 0), # conv2\n",
    "    (2, 2, 0), # pool2\n",
    "    (3, 1, 0), # conv3\n",
    "    (3, 1, 0), # conv4\n",
    "    (3, 1, 0), # conv5\n",
    "    (2, 2, 0), # pool5\n",
    "])\n",
    "\n",
    "cnn = CNN(num_classes)\n",
    "x = torch.randn(32, 3, input_size, input_size)\n",
    "y = cnn(x)\n",
    "print(f'CNN output shape: {y.shape}')\n",
    "\n",
    "rnn = RNN(input_size, num_classes)\n",
    "\n",
    "num_video_frames = 500\n",
    "x = torch.randn(32, num_video_frames, input_size)\n",
    "y = rnn(x)\n",
    "print(f'RNN output shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76ec27",
   "metadata": {},
   "source": [
    "## Two Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00d0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# In: 216 x 216\n",
      "Fractional output size: 105.5\n",
      "nn.Conv2d(..., 7, 2, 0), # 105 x 105\n",
      "Fractional output size: 52.5\n",
      "nn.Conv2d(..., 2, 2, 0), # 52 x 52\n",
      "Fractional output size: 24.5\n",
      "nn.Conv2d(..., 5, 2, 0), # 24 x 24\n",
      "nn.Conv2d(..., 2, 2, 0), # 12 x 12\n",
      "nn.Conv2d(..., 3, 1, 1), # 12 x 12\n",
      "nn.Conv2d(..., 3, 1, 1), # 12 x 12\n",
      "nn.Conv2d(..., 3, 1, 1), # 12 x 12\n",
      "nn.Conv2d(..., 2, 2, 0), # 6 x 6\n",
      "# Out: 6 x 6\n"
     ]
    }
   ],
   "source": [
    "# Spatial CNN architecture\n",
    "check_Conv2d_architecture(input_size, [\n",
    "    (7, 2, 0), # conv1\n",
    "    (2, 2, 0), # pool1\n",
    "    (5, 2, 0), # conv2\n",
    "    (2, 2, 0), # pool2\n",
    "    (3, 1, 1), # conv3\n",
    "    (3, 1, 1), # conv4\n",
    "    (3, 1, 1), # conv5\n",
    "    (2, 2, 0), # pool5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f70c80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two stream output shape: torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "two_stream = two_stream_model(num_classes)\n",
    "\n",
    "temporal_input = torch.randn(32, 18, input_size, input_size)\n",
    "spatial_input = torch.randn(32, 3, input_size, input_size)\n",
    "y = two_stream(spatial_input, temporal_input)\n",
    "print(f'Two stream output shape: {y.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
