import os
import numpy as np
import random
import scipy.misc


def sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
    Read sequence data of batch_size into memory
    :param data_list: The data generated by get_data_list
    :param batch_size:
    :param input_shape: tuple: the shape of numpy ndarray, e.g. (seq_len, 216, 216, 3) for sequence
                        or (216, 216, 18) for optical flow data
    :param num_classes:
    :return:
    '''
    if isinstance(input_shape, tuple):
        x_shape = (batch_size,) + input_shape
    else:
        raise ValueError('Input shape is neither 1D or 3D')
    y_shape = (batch_size, num_classes)
    index = 0
    while True:
        batch_x = np.ndarray(x_shape)
        batch_y = np.zeros(y_shape)
        for i in range(batch_size):
            step = random.randint(1, len(data_list) - 1)  # approach a random-size step to get the next video sample
            index = (index + step) % len(data_list)
            clip_dir, clip_class = data_list[index]
            batch_y[i, clip_class - 1] = 1
            clip_dir = os.path.splitext(clip_dir)[0] + '.npy'
            # avoid endless loop
            count = 0
            while not os.path.exists(clip_dir):
                count += 1
                if count > 20:
                    raise FileExistsError('Too many file missing')
                index = (index + 1) % len(data_list)
                clip_dir, class_idx = data_list[index]
            clip_data = np.load(clip_dir)
            if clip_data.shape != batch_x.shape[1:]:
                raise ValueError('The number of time sequence is inconsistent with the video data')
            batch_x[i] = clip_data
        yield batch_x, batch_y


def image_from_sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
        Read one frame in the sequence data into memory
        input_shape: (seq_len,) + img_size
    '''
    batch_image_shape = (batch_size,) + input_shape[1:]
    batch_image = np.ndarray(batch_image_shape)

    video_gen = sequence_generator(data_list, batch_size, input_shape, num_classes)

    while True:
        batch_video, batch_label = next(video_gen)
        for idx, video in enumerate(batch_video):
            sample_frame_idx = random.randint(0, input_shape[0] - 1)
            sample_frame = video[sample_frame_idx]
            batch_image[idx] = sample_frame

        yield batch_image, batch_label


def two_stream18_generator(list_dir, spatial_dir, temporal_dir, batch_size, spatial_shape, temporal_shape, num_classes):
    '''
    
    :param list_dir: '.../testlist.txt'
    :param spatial_dir: '.../test/'
    :param temporal_dir: '.../test/'
    :param batch_size: 
    :param input_shape: 
    :param num_classes: 
    :return: 
    '''
    with open(list_dir) as fo:
        test_list = [line for line in fo]

    spatial_x_shape = (batch_size,) + spatial_shape
    temporal_x_shape = (batch_size,) + temporal_shape
    y_shape = (batch_size, num_classes)

    while True:
        spatial_x = np.zeros(spatial_x_shape)
        temporal_x = np.zeros(temporal_x_shape)
        two_stream_x = [spatial_x, temporal_x]
        two_stream_y = np.zeros(y_shape)
        for i in range(batch_size):
            clip_name, clip_index = random.choice(test_list).split()
            clip_name = clip_name[:clip_name.find('.')] + '.npy'
            clip_spatial_dir = os.path.join(spatial_dir, clip_name)
            clip_temporal_dir = os.path.join(temporal_dir, clip_name)
            # read spatial data
            seq_data = np.load(clip_spatial_dir)
            spatial_x[i] = seq_data[random.randrange(seq_data.shape[0])]
            # read temporal data
            temporal_x[i] = np.load(clip_temporal_dir)

            two_stream_y[i][int(clip_index) - 1] = 1
        yield two_stream_x, two_stream_y


def get_data_list(list_dir, video_dir):
    '''
    Input parameters:
    list_dir: 'root_dir/data/ucfTrainTestlist'
    video_dir: directory that stores source train and test data
    Return value:
    test_data/train_data: list of tuples (clip_dir, class index)
    class_index: dictionary of mapping (class_name->class_index)
    '''
    train_dir = os.path.join(video_dir, 'train')
    test_dir = os.path.join(video_dir, 'test')
    testlisttxt = 'testlist.txt'
    trainlisttxt = 'trainlist.txt'

    testlist = []
    txt_path = os.path.join(list_dir, testlisttxt)
    with open(txt_path) as fo:
        for line in fo:
            testlist.append(line[:line.rfind(' ')])

    trainlist = []
    txt_path = os.path.join(list_dir, trainlisttxt)
    with open(txt_path) as fo:
        for line in fo:
            trainlist.append(line[:line.rfind(' ')])

    class_index = dict()
    class_dir = os.path.join(list_dir, 'classInd.txt')
    with open(class_dir) as fo:
        for line in fo:
            class_number, class_name = line.split()
            class_number = int(class_number)
            class_index[class_name] = class_number

    train_data = []
    for i, clip in enumerate(trainlist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(train_dir, clip)
        train_data.append((dst_dir, class_index[clip_class]))

    test_data = []
    for i, clip in enumerate(testlist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(test_dir, clip)
        test_data.append((dst_dir, class_index[clip_class]))

    return train_data, test_data, class_index


if __name__ == '__main__':
    image_size = (216, 216, 3)

    data_dir = '/home/changan/ActionRecognition/data'
    list_dir = os.path.join(data_dir, 'ucfTrainTestlist')

    test_list = os.path.join(list_dir, 'testlist.txt')
    frames_dir = '/home/changan/ActionRecognition/data/UCF-Preprocessed-OF/test'
    flow_dir = '/home/changan/ActionRecognition/data/OF_data/test'
    BatchSize = 32
    N_CLASSES = 174
    generator = two_stream18_generator(test_list, frames_dir, flow_dir, BatchSize,
                                       (216, 216, 3), (216, 216, 18), N_CLASSES)

    for i in range(10):
        x, y = next(generator)